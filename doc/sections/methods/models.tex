Durante el entrenamiento se utilizaron dos modelos. Por un lado,
se entrenó un \textit{Naïve Bayes Multinomial}, de tipo generativo,
y, por otro, una Regresión Logística, perteneciente a los modelos de tipo
predictivo. \todo{modelos generativos vs. predictivos}
\par
Dado que, en términos concretos, este trabajo pretende evaluar la adecuación
de determinados rasgos para caracterizar un discurso a favor o en contra de
cierta ley, para el entremiento se despreciaron aquellos discursos pertenecientes
a senadores que estuvieron ausentes durante la votación o se abstuvieron de la misma.
Lo que resultó en un conjunto de datos de 199 discursos. De estos, el $20\percentsign$
fue separado para usar como conjunto de testeo o \textit{held-out} y el $80\percentsign$
restante se utilizó para el entrenamiento.
\par
Como primer paso, previo al ajuste de los modelos, se realizó un proceso de
codificación o \textit{encoding}. La variable objetivo \texttt{voto} fue mapeada a los
valores $1$ (`positivo') y $0$ (`negativo'). A su vez, cada texto fue vectorizado
utilizando los \textit{features} generados a través del método de proporciones
con remoción de \textit{stopwords} según la Ley de Zipf, para lo cual se seleccionaron
los $250$ lemas
\footnote{No olvidar que estos lemas incluyen también la etiqueta \textit{POS}.} 
más representativos de los discursos a favor y de aquellos
en contra, por lo que los vectores resultantes constan de $500$
dimesiones. Ambas transformaciones se realizaron con métodos provistos por la librería
\textit{scikit-learn}.
\par
Con los discursos así vectorizados, se procedió a realizar una búsqueda exhaustiva de los
mejores hiperparámetros para cada modelos. Para esto, se empleó el método de validación
cruzada, para lo cual se divió el \textit{dataset} de entrenamiento en 5 y se realizaron,
a su vez, 5 entrenamientos: en cada uno se entrenó con 4 subconjuntos y se validó con el
subconjunto restante, utilizando en cada iteración un subconjunto diferente para la
validación. En el caso de \textit{Naïve Bayes} se evaluaron distintos valores para el
parámetro $\alpha$ ($0.01$, $0.1$, $1.0$), el cual agrega un suavizado.\todo{explicar
mejor}. En cuanto a la Regresión Logística, se evaluaron diferentes penalidades
(`L1' y `L2') y distintos valores para la intensidad de la regularización
($0.1$, $0.5$, $1.0$)\todo{explicar mejor}. En todos los casos se fijó una semilla
para garantizar la replicabilidad de los métodos aplicados.