Luego del proceso de anotaci\'on y correcci\'on de lemas y etiquetas gramaticales,
se extrajeron algunas m\'etricas de resumen y se realizaron gr\'aficos con el fin de
comprender qu\'e distribuci\'on presentaban dichas etiquetas utilizadas y cu\'antos de los
datos etiquetdados de forma autom\'atica requirieron alguna correcci\'on, ya fuera en el
lema asignado, ya en la etiqueta gramatical predicha.
\par
En total, se revisaron 8324 anotaciones\footnote{Cada anotaci\'on est\'a dada por
la ocurrencia \textit{cruda} de la palabra, la etiqueta (o etitquetas, si el modelo
predijo m\'as de una posible) de esa palabra en los discursos en los que fue vista y el
lema (o lemas, si se predijo m\'as de uno) para esa palabra en tales contextos.}.
De ellas, se despreciaron 211 cadenas de caracteres ($1.86\percentsign$)
\footnote{Remitirse a \ref{appendix-annotation} para un detalle de las palabras
despreciadas.}. De las palabras que se persistieron para el an\'alisis,
el $20.4\percentsign$ requiri\'o una correcci\'on en el lema predicho.
De estas correcciones, el $27.8\percentsign$ de los casos corresponden a
palabras para las cuales el modelo realiz\'o diferentes predicciones en los distintos
contextos de aparici\'on y una de estas predicciones fue acertada. Estos casos se
consideraron un error porque, si bien el modelo predijo al menos una vez el lema correcto,
no lo hizo de forma consistente. El $72.2\percentsign$ de los errores
restantes fueron casos en los que el modelo no logr\'o predecir el lema correcto en
ninguna situaci\'on.
Respecto de las etiquetas \textit{POS} se procedi\'o con un an\'alisis similar.
El $12.35\percentsign$ de las palabras etiquetadas de manera autom\'atica requiri\'o
una correcci\'on. De estos casos de error, el $71\percentsign$ de las palabras
constituyen casos en los cuales el modelo predijo distintas etiquetas en los contextos
observados y una de ellas result\'o ser la adecuada.
En el resto de los casos ($29\percentsign$) el modelo no fue capaz de
identificar la etiqueta adecuada en ninguna de sus predicciones.
\par
Al final del procedimiento se obtuvo un conjunto de 4889 \textit{tokens} \'unicos,
donde la unicidad hace referencia al lema y a la etiqueta gramatical asignada.
En el an\'alisis exploratorio realizado para la descripci\'on de los datos, la unicidad
de los \textit{tokens} estaba dada por la igualdad en la secuencia de caracteres
en la ocurrencia efectiva de la palabra: all\'i `suma' se considera
una sola vez, independientemente de si, en sus distintas ocurrencias, refiere al
verbo (en la tercera persona singular del verbo `sumar') o al nombre
(\textit{``acci\'on y efecto de sumar''}\footnote{\Citeauthor{rae23diccionario}.}). Al
agrupar los \textit{tokens} por lema y etiqueta gramatical, estas dos
ocurrencias son consideradas por separado, dado que se toma en cuenta
`suma (\textit{NOUN})' y `sumar (\textit{VERB})'
\footnote{\textit{`Noun'} y \textit{`verb'} refieren a las clases `nombre'
(o `sustantivo') y `verbo', respectivamente. Otras clases frecuentes son \textit{`adj'},
por `adjetivo', y \textit{`adv'}, por `adverbio'. Para una lista completa
de las posibles etiquetas, visitar: \url{https://universaldependencies.org/u/pos/}
[\'ultimo acceso: 15--10--2024].}. La figura \ref{fig-distrib-unique-tokens} refleja el contraste
en la longitud de discursos al ser medidos con ambos enfoques.
All\'i se puede observar que las longitudes medidas considerando lemas y etiquedas
\textit{POS} reflejan valores menores\footnote{Es preciso recordar aqu\'i
que, si bien el uso de etiquetas \textit{POS} puede llevar a considerar
como dos o m\'as palabras lo que, en el an\'alisis previo se consideraba
como una palabra \'unica, el uso de los lemas (en contraste con
las palabras que reflejan acciedentes morfol\'ogicos) reduce en gran
medida el vocabulario de los documentos.}.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.45]{../visualizations/distrib_tokes_vs_lemma_pos/distrib_tokens_vs_lemma_pos.png}
\caption{Distribuci\'on \textit{tokens} \'unicos aplicando distintos criterios de unicidad.
En la figura de la izquierda los \textit{tokens} se miden en palabras y, en la de la
derecha, a lemas con su correspondiente etiqueta \textit{POS}. El eje de ordenadas
(eje \textit{y}) indica la cantidad de \textit{tokens} en cada caso.}
\label{fig-distrib-unique-tokens}
\end{figure}