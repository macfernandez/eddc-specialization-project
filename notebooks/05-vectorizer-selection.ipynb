{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de vectorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, f1_score, precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from config import DATA_PATH, MODELS_PATH, VISUALIZATIONS_PATH\n",
    "from notebooks.src.vectorizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(DATA_PATH, \"session_speech.csv\")\n",
    "data = pd.read_csv(data_path, converters={\"speech_lemma_pos\":eval})\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data[(data.speech.notna()) & (~data.vote.isin([\"abstención\", \"ausente\"]))]\n",
    "    .reset_index(drop=True)\n",
    "    .assign(\n",
    "        speech_lemma_pos=lambda x: x.speech_lemma_pos.apply(\n",
    "            lambda z: \" \".join([\"_\".join(i) for i in z])\n",
    "        )\n",
    "    )\n",
    ")\n",
    "data[[\"speech_lemma_pos\", \"vote\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.vote.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación en _train_ y _test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_index, X_test_index = train_test_split(\n",
    "    data.index,\n",
    "    test_size=.2,\n",
    "    random_state=6300,\n",
    "    shuffle=True,\n",
    "    stratify=data.vote\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, name in zip([X_train_index, X_test_index], [\"entrenamiento\", \"testeo\"]):\n",
    "    print(f\"** Cantidad de datos en conjunto de {name}: {index.shape[0]}\")\n",
    "    print(\"** Distribución de la variable target:\")\n",
    "    print(f\"{data.loc[index, 'vote'].value_counts(normalize=True).to_frame()}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = os.path.join(MODELS_PATH, \"index\")\n",
    "os.makedirs(INDEX, exist_ok=True)\n",
    "\n",
    "for file in [\"X_train_index\", \"X_test_index\"]:\n",
    "    dataset = eval(file)\n",
    "    dataset.to_series().to_csv(os.path.join(INDEX, f\"{file}.csv\"), header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Encoding_ de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable _target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "data[\"target\"] = le.fit_transform(data.vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in data.vote.unique():\n",
    "    print(f\"Categoría {value} ---> {le.transform([value])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_path = os.path.join(MODELS_PATH, \"labelencoder.pkl\")\n",
    "_ = joblib.dump(le, le_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de vectorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [\n",
    "    {\"name\": \"Frecuencias absolutas\",\"class\": CustomFrequenciesVectorizer, \"kwargs\": {}},\n",
    "    {\"name\": \"Proporciones\",\"class\": CustomProportionsVectorizer, \"kwargs\": {}},\n",
    "    {\"name\": \"Proporciones\",\"class\": CustomProportionsVectorizer, \"kwargs\": {\"stop_words\": \"nltk\"}},\n",
    "    {\"name\": \"Proporciones\",\"class\": CustomProportionsVectorizer, \"kwargs\": {\"stop_words\": \"zipf\"}},\n",
    "    {\"name\": \"Ratio de odds\",\"class\": CustomOddsRatioVectorizer, \"kwargs\": {}},\n",
    "    {\"name\": \"Ratio de log odds\",\"class\": CustomLogOddsRatioVectorizer, \"kwargs\": {}},\n",
    "    {\"name\": \"Ratio de log odds\",\"class\": CustomLogOddsRatioVectorizer, \"kwargs\": {\"smooth\": .5}},\n",
    "    {\"name\": \"Word scores\",\"class\": CustomWordScoresVectorizer, \"kwargs\": {}},\n",
    "    {\"name\": \"TF-IDF\",\"class\": CustomTfidfVectorizer, \"kwargs\": {}},\n",
    "    {\"name\": \"TF-IDF\",\"class\": CustomTfidfVectorizer, \"kwargs\": {\"log_idf\": True}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = os.path.join(MODELS_PATH, \"features_selection\")\n",
    "os.makedirs(FEATURES, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 6300\n",
    "\n",
    "X_trainset, y_trainset = (\n",
    "    data.loc[X_train_index, \"speech_lemma_pos\"], data.loc[X_train_index, \"target\"]\n",
    ")\n",
    "cv_method = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "scoring_method = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"f1\": \"f1\",\n",
    "    \"f1_micro\": make_scorer(f1_score, average=\"micro\"),\n",
    "    \"f1_macro\": make_scorer(f1_score, average=\"macro\"),\n",
    "    \"precision\": make_scorer(precision_score),\n",
    "    \"precision_micro\": make_scorer(precision_score, average=\"micro\"),\n",
    "    \"precision_macro\": make_scorer(precision_score, average=\"macro\"),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"recall_micro\": make_scorer(recall_score, average=\"micro\"),\n",
    "    \"recall_macro\": make_scorer(recall_score, average=\"macro\"),\n",
    "    \"roc_auc_micro\": make_scorer(roc_auc_score, average=\"micro\"),\n",
    "    \"roc_auc_macro\": make_scorer(roc_auc_score, average=\"macro\"),\n",
    "}\n",
    "\n",
    "cv_results_to_compare = pd.DataFrame()\n",
    "for vectorizer in vectorizers:\n",
    "    kwargs = deepcopy(vectorizer.get(\"kwargs\"))\n",
    "    stop_words = kwargs.pop(\"stop_words\", None)\n",
    "    if stop_words == \"nltk\":\n",
    "        kwargs[\"stop_words\"] = stopwords.words(\"spanish\")\n",
    "    elif stop_words == \"zipf\":\n",
    "        kwargs[\"custom_stop_words\"] = \"zipf\"\n",
    "    pipeline = Pipeline([\n",
    "        (\n",
    "            \"vectorizer\",\n",
    "            vectorizer[\"class\"](\n",
    "                positive_values=1, dimension=300, **kwargs\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(random_state=SEED)\n",
    "        )\n",
    "    ])\n",
    "    print(f\"-- Running cross_validate for {pipeline.steps[0][1]}\")\n",
    "    cv_results = cross_validate(\n",
    "        pipeline, X_trainset, y_trainset, cv=cv_method, \n",
    "        n_jobs=-1, return_train_score=True, scoring=scoring_method\n",
    "    )\n",
    "    cv_results_df = (\n",
    "        pd.DataFrame(cv_results)\n",
    "        .assign(split=lambda x: x.index+1)\n",
    "    )\n",
    "    cv_results_df[\"vectorizer\"] = vectorizer[\"name\"]\n",
    "    cv_results_df[\"kwargs\"] = pd.Series([vectorizer[\"kwargs\"]]*len(cv_results_df))\n",
    "    cv_results_to_compare = pd.concat(\n",
    "        [cv_results_to_compare, cv_results_df], ignore_index=True\n",
    "    )\n",
    "file_path = os.path.join(FEATURES, \"features_selection.csv\")\n",
    "cv_results_to_compare.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_to_compare = (\n",
    "    cv_results_to_compare\n",
    "    .assign(\n",
    "        kwargs_=lambda x: x.kwargs.apply(\n",
    "            lambda z: \", \".join([f\"{k}={v}\" for k, v in z.items()])\n",
    "        ),\n",
    "        title=lambda x: x.apply(\n",
    "            lambda z: f\"{z.vectorizer} ({z.kwargs_})\" if z.kwargs else z.vectorizer,\n",
    "            axis=1)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    cv_results_to_compare[[\"title\", \"fit_time\", \"split\"]],\n",
    "    y=\"title\", x=\"fit_time\",\n",
    "    estimator=\"mean\", errorbar=\"sd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    cv_results_to_compare[[\"title\", \"fit_time\", \"split\"]],\n",
    "    y=\"fit_time\", x=\"split\",\n",
    "    hue=\"title\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PLOTS = os.path.join(VISUALIZATIONS_PATH, \"features\")\n",
    "os.makedirs(FEATURES_PLOTS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_cols = cv_results_to_compare.filter(like=\"train_\").columns.sort_values().to_list()\n",
    "test_scores_cols = cv_results_to_compare.filter(like=\"test_\").columns.sort_values().to_list()\n",
    "\n",
    "for i in range(len(train_scores_cols)):\n",
    "    # mean and sd\n",
    "    metric = re.sub(\"train_\",\"\",train_scores_cols[i]).replace(\"_\", \" \")\n",
    "    title = metric.capitalize()\n",
    "    fig, axs = plt.subplots(1,2, figsize=(9,3), sharey=True)\n",
    "    sns.barplot(\n",
    "        cv_results_to_compare[[\"title\", train_scores_cols[i], \"split\"]],\n",
    "        hue=\"title\", y=train_scores_cols[i], legend=False,\n",
    "        estimator=\"mean\", errorbar=\"sd\", ax=axs[0], alpha=.7\n",
    "    )\n",
    "    sns.barplot(\n",
    "        cv_results_to_compare[[\"title\", test_scores_cols[i], \"split\"]],\n",
    "        hue=\"title\", y=test_scores_cols[i],\n",
    "        estimator=\"mean\", errorbar=\"sd\", ax=axs[1], alpha=.7\n",
    "    )\n",
    "    axs[0].set_ylabel(\"\")\n",
    "    axs[0].set_title(\"Entrenamiento\")\n",
    "    axs[1].set_title(\"Validación\")\n",
    "    suptitle = fig.suptitle(f\"{title}\", y=1.05, style=\"italic\")\n",
    "    lgd = plt.legend(loc=\"lower center\", bbox_to_anchor=(-0.1, -0.6), ncol=2)\n",
    "    plt.savefig(\n",
    "        os.path.join(FEATURES_PLOTS, f\"{metric}_mean_sd.png\"),\n",
    "        bbox_extra_artists=[lgd,suptitle], bbox_inches='tight'\n",
    "    )\n",
    "    # deaggregated\n",
    "    fig, bxs = plt.subplots(1,2, figsize=(9,3), sharey=True)\n",
    "    sns.lineplot(\n",
    "        cv_results_to_compare[[\"title\", train_scores_cols[i], \"split\"]],\n",
    "        y=train_scores_cols[i], x=\"split\",\n",
    "        hue=\"title\", ax=bxs[0], legend=False, alpha=.7\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        cv_results_to_compare[[\"title\", test_scores_cols[i], \"split\"]],\n",
    "        y=test_scores_cols[i], x=\"split\", alpha=.7,\n",
    "        hue=\"title\", ax=bxs[1]\n",
    "    )\n",
    "    bxs[0].set_ylabel(\"\")\n",
    "    bxs[0].set_xlabel(\"\")\n",
    "    bxs[1].set_xlabel(\"\")\n",
    "    bxs[0].set_title(\"Entrenamiento\")\n",
    "    bxs[1].set_title(\"Validación\")\n",
    "    suptitle = fig.suptitle(f\"{title}\", y=1.05, style=\"italic\")\n",
    "    lgd = plt.legend(loc=\"lower center\", bbox_to_anchor=(-0.1, -0.65), ncol=2)\n",
    "    plt.savefig(\n",
    "        os.path.join(FEATURES_PLOTS, f\"{metric}_by_split.png\"),\n",
    "        bbox_extra_artists=[lgd,suptitle], bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = (\n",
    "    cv_results_to_compare\n",
    "    .drop(columns=[\"vectorizer\", \"kwargs\", \"kwargs_\", \"split\"])\n",
    "    .groupby(\"title\")\n",
    "    [[\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\", \"test_f1_micro\", \"test_f1_macro\"]]\n",
    "    .agg([\"mean\"])\n",
    ")\n",
    "N.columns = list(map(lambda x: x.strip(\"test_\"),N.columns.droplevel(1)))\n",
    "N.rename_axis(index=\"vectorizador\", inplace=True)\n",
    "N.style.highlight_max(color='green')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddc-tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
