{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Datasets_ de entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Any\n",
    "from copy import deepcopy\n",
    "from string import punctuation\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from config import DATA_PATH, VISUALIZATIONS_PATH, MODELS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'vote', 'senator', 'province', 'party', 'party_family',\n",
       "       'speaker', 'speech', 'speech_preprocessed', 'speech_lemmas',\n",
       "       'speech_pos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(DATA_PATH, \"session_speech.csv\")\n",
    "data = pd.read_csv(data_path)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>vote</th>\n",
       "      <th>senator</th>\n",
       "      <th>province</th>\n",
       "      <th>party</th>\n",
       "      <th>party_family</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>speech_preprocessed</th>\n",
       "      <th>speech_lemmas</th>\n",
       "      <th>speech_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana Claudia Almirón</td>\n",
       "      <td>positivo</td>\n",
       "      <td>ALMIRÓN ANA CLAUDIA</td>\n",
       "      <td>CORRIENTES</td>\n",
       "      <td>ALIANZA FRENTE PARA LA VICTORIA</td>\n",
       "      <td>Frente para la victoria</td>\n",
       "      <td>Almirón</td>\n",
       "      <td>Hace dos años, tuvimos una sesión histórica cu...</td>\n",
       "      <td>hace dos años tuvimos una sesión histórica cua...</td>\n",
       "      <td>hacer año tener una sesión histórica cuando de...</td>\n",
       "      <td>VERB NOUN VERB DET NOUN ADJ SCONJ VERB ADP ADJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roberto Gustavo Basualdo</td>\n",
       "      <td>negativo</td>\n",
       "      <td>BASUALDO ROBERTO GUSTAVO</td>\n",
       "      <td>SAN JUAN</td>\n",
       "      <td>ALIANZA CAMBIEMOS SAN JUAN</td>\n",
       "      <td>Juntos por el cambio</td>\n",
       "      <td>Basualdo</td>\n",
       "      <td>Gracias, señor presidente. Hoy es un día en el...</td>\n",
       "      <td>gracias señor presidente hoy es un día en el q...</td>\n",
       "      <td>gracia señor presidente hoy ser un día en el q...</td>\n",
       "      <td>NOUN NOUN NOUN ADV VERB DET NOUN ADP DET SCONJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name      vote                   senator    province  \\\n",
       "0       Ana Claudia Almirón  positivo       ALMIRÓN ANA CLAUDIA  CORRIENTES   \n",
       "1  Roberto Gustavo Basualdo  negativo  BASUALDO ROBERTO GUSTAVO    SAN JUAN   \n",
       "\n",
       "                             party             party_family   speaker  \\\n",
       "0  ALIANZA FRENTE PARA LA VICTORIA  Frente para la victoria   Almirón   \n",
       "1       ALIANZA CAMBIEMOS SAN JUAN     Juntos por el cambio  Basualdo   \n",
       "\n",
       "                                              speech  \\\n",
       "0  Hace dos años, tuvimos una sesión histórica cu...   \n",
       "1  Gracias, señor presidente. Hoy es un día en el...   \n",
       "\n",
       "                                 speech_preprocessed  \\\n",
       "0  hace dos años tuvimos una sesión histórica cua...   \n",
       "1  gracias señor presidente hoy es un día en el q...   \n",
       "\n",
       "                                       speech_lemmas  \\\n",
       "0  hacer año tener una sesión histórica cuando de...   \n",
       "1  gracia señor presidente hoy ser un día en el q...   \n",
       "\n",
       "                                          speech_pos  \n",
       "0  VERB NOUN VERB DET NOUN ADJ SCONJ VERB ADP ADJ...  \n",
       "1  NOUN NOUN NOUN ADV VERB DET NOUN ADP DET SCONJ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    data[(data.speech.notna()) & (~data.vote.isin([\"abstención\", \"ausente\"]))]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote\n",
       "positivo    0.557789\n",
       "negativo    0.442211\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vote.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación en _train_ y _test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_index, X_test_index = train_test_split(\n",
    "    data.index,\n",
    "    test_size=.2,\n",
    "    random_state=6300,\n",
    "    shuffle=True,\n",
    "    stratify=data.vote\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Cantidad de datos en conjunto de entrenamiento: 159\n",
      "** Distribución de la variable target:\n",
      "          proportion\n",
      "vote                \n",
      "positivo    0.559748\n",
      "negativo    0.440252\n",
      "\n",
      "** Cantidad de datos en conjunto de testeo: 40\n",
      "** Distribución de la variable target:\n",
      "          proportion\n",
      "vote                \n",
      "positivo        0.55\n",
      "negativo        0.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, name in zip([X_train_index, X_test_index], [\"entrenamiento\", \"testeo\"]):\n",
    "    print(f\"** Cantidad de datos en conjunto de {name}: {index.shape[0]}\")\n",
    "    print(\"** Distribución de la variable target:\")\n",
    "    print(f\"{data.loc[index, 'vote'].value_counts(normalize=True).to_frame()}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = os.path.join(MODELS_PATH, \"index\")\n",
    "os.makedirs(INDEX, exist_ok=True)\n",
    "\n",
    "for file in [\"X_train_index\", \"X_test_index\"]:\n",
    "    dataset = eval(file)\n",
    "    dataset.to_series().to_csv(os.path.join(INDEX, f\"{file}.csv\"), header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Encoding_ de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etiquetas POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065321</td>\n",
       "      <td>0.051069</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.179929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.079012</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>0.246914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074301</td>\n",
       "      <td>0.060315</td>\n",
       "      <td>0.217657</td>\n",
       "      <td>0.151224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101869</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.236449</td>\n",
       "      <td>0.139252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091278</td>\n",
       "      <td>0.067613</td>\n",
       "      <td>0.185260</td>\n",
       "      <td>0.187289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ADJ       ADV      NOUN      VERB\n",
       "0  0.065321  0.051069  0.204869  0.179929\n",
       "1  0.061728  0.079012  0.167901  0.246914\n",
       "2  0.074301  0.060315  0.217657  0.151224\n",
       "3  0.101869  0.042056  0.236449  0.139252\n",
       "4  0.091278  0.067613  0.185260  0.187289"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm=\"l1\", use_idf=False, smooth_idf=False, sublinear_tf=False)\n",
    "X = vectorizer.fit_transform(data.speech_pos)\n",
    "pos = (\n",
    "    pd.DataFrame(X.toarray(), columns=map(str.upper,vectorizer.get_feature_names_out()))\n",
    "    [[\"ADJ\", \"ADV\", \"NOUN\", \"VERB\"]]\n",
    ")\n",
    "pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS = os.path.join(VISUALIZATIONS_PATH, \"stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proporciones sin _stopwords_ (Zipf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>total</th>\n",
       "      <th>diff</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abajo</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandonada</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandonado</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandono</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word     total      diff       pos      neg\n",
       "0       abajo  0.693147 -0.000031  0.000039  0.00007\n",
       "1  abandonada  0.000000  0.000039  0.000039  0.00000\n",
       "2  abandonado  0.000000  0.000039  0.000039  0.00000\n",
       "3   abandonar  0.000000 -0.000070  0.000000  0.00007\n",
       "4    abandono  0.000000 -0.000070  0.000000  0.00007"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions = pd.read_csv(os.path.join(STATS, \"proporciones_sin_stopwords_zipf.csv\"))\n",
    "proportions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = proportions.nlargest(n=250, columns=[\"diff\"], keep=\"all\").word.to_list()\n",
    "neg_words = proportions.nsmallest(n=250, columns=[\"diff\"], keep=\"all\").word.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cantidad de rasgos\n",
    "proportions_words = pos_words+neg_words\n",
    "len(proportions_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ratio de _log-odds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>total</th>\n",
       "      <th>diff</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abajo</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-0.615795</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandonada</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandonado</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandono</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word     total      diff       pos       neg\n",
       "0       abajo  0.693147 -0.615795  0.000019  0.000035\n",
       "1  abandonada  0.000000       inf  0.000019  0.000000\n",
       "2  abandonado  0.000000       inf  0.000019  0.000000\n",
       "3   abandonar  0.000000      -inf  0.000000  0.000035\n",
       "4    abandono  0.000000      -inf  0.000000  0.000035"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_odds = pd.read_csv(os.path.join(STATS, \"log_odds.csv\"))\n",
    "log_odds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>total</th>\n",
       "      <th>diff</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandono</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aberración</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abiertamente</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abocado</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>zimmermann</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>ángulo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4762</th>\n",
       "      <td>éxito</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>útil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  total  diff  pos       neg\n",
       "3        abandonar    0.0  -inf  0.0  0.000035\n",
       "4         abandono    0.0  -inf  0.0  0.000035\n",
       "8       aberración    0.0  -inf  0.0  0.000035\n",
       "11    abiertamente    0.0  -inf  0.0  0.000035\n",
       "14         abocado    0.0  -inf  0.0  0.000035\n",
       "...            ...    ...   ...  ...       ...\n",
       "4749    zimmermann    0.0  -inf  0.0  0.000035\n",
       "4751          zoom    0.0  -inf  0.0  0.000035\n",
       "4754        ángulo    0.0  -inf  0.0  0.000035\n",
       "4762         éxito    0.0  -inf  0.0  0.000035\n",
       "4780          útil    0.0  -inf  0.0  0.000035\n",
       "\n",
       "[837 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_odds.nlargest(n=200, columns=[\"diff\", \"total\"], keep=\"all\") #.word.to_list()\n",
    "log_odds.nsmallest(n=200, columns=[\"diff\", \"total\"], keep=\"all\") #.word.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable _target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "data[\"target\"] = le.fit_transform(data.vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in data.vote.unique():\n",
    "    print(f\"Categoría {value} ---> {le.transform([value])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gridsearch(clf: Any, clf_params: dict[str, list]) -> GridSearchCV:\n",
    "    params = {\n",
    "        \"tfidf__min_df\": [0.1, 0.3, 0.5, 0.7],\n",
    "        \"tfidf__norm\": [\"l1\", \"l2\"],\n",
    "        \"tfidf__smooth_idf\": [False, True],\n",
    "        \"tfidf__sublinear_tf\": [False, True],\n",
    "        \"tfidf__min_df\": [0.05, 0.1],\n",
    "        **clf_params\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        (\n",
    "            'tfidf',\n",
    "            TfidfVectorizer(\n",
    "                lowercase=True,\n",
    "                preprocessor=preprocess\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            'clf',\n",
    "            clf\n",
    "        )\n",
    "    ])\n",
    "    return GridSearchCV(\n",
    "        pipeline,\n",
    "        params,\n",
    "        scoring='f1',\n",
    "        cv=5,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "def build_results_df(cv_results: dict[str, np.ndarray]) -> pd.DataFrame:\n",
    "    df_cv_results = pd.DataFrame(cv_results)\n",
    "    param_cols = df_cv_results.filter(regex=\"param_\").columns.tolist()\n",
    "    df_cv_results.drop(columns=param_cols, inplace=True)\n",
    "    df_cv_results[\"params\"] = (\n",
    "        df_cv_results\n",
    "        .params\n",
    "        .apply(lambda x: \"-\".join([f\"{k}={v}\" for k, v in x.items()]))\n",
    "    )\n",
    "    df_cv_results.set_index(\"params\", inplace=True)\n",
    "    df_cv_results.sort_values(by=\"rank_test_score\", inplace=True)\n",
    "    df_cv_results = df_cv_results[df_cv_results.columns.sort_values().tolist()]\n",
    "    return df_cv_results\n",
    "\n",
    "\n",
    "def build_results_df2plot(results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    split_cols = results_df.filter(regex=r\"(split\\d+\\_test)\").columns.to_list()\n",
    "    return (\n",
    "        pd.concat([\n",
    "            results_df.nlargest(3, \"mean_test_score\"),\n",
    "            results_df.nsmallest(3, \"std_test_score\")\n",
    "        ])\n",
    "        .drop_duplicates(keep=\"first\")\n",
    "        .reset_index()\n",
    "        .melt(\n",
    "            id_vars = [\"params\"],\n",
    "            value_vars = split_cols,\n",
    "            var_name = \"measure\"\n",
    "        )\n",
    "        .merge(\n",
    "            results_df[[\"mean_test_score\", \"std_test_score\"]],\n",
    "            left_on = \"params\", right_index = True\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_results(results_df2plot: pd.DataFrame, clf: str, file_name: str) -> None:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(9,3))\n",
    "    for params, df in results_df2plot.groupby(\"params\"):\n",
    "        _df = df[[\"params\", \"mean_test_score\", \"std_test_score\"]].drop_duplicates(keep=\"first\")\n",
    "        axs[0].errorbar(\n",
    "            x=_df.mean_test_score,\n",
    "            xerr=_df.std_test_score,\n",
    "            y=_df.params,\n",
    "            fmt=\"o\",\n",
    "            label=params\n",
    "        )\n",
    "        axs[1].errorbar(\n",
    "            x=df.measure,\n",
    "            y=df.value,\n",
    "            label=params\n",
    "        )\n",
    "    axs[0].set_yticklabels(\"F1 score\")\n",
    "    axs[0].set_yticks([])\n",
    "    axs[0].set_xlabel(\"\")\n",
    "    axs[0].set_title(\"Promedio y desvío\")\n",
    "    axs[1].set_xticklabels([\n",
    "        \"split {n}\".format(n=re.search(r'\\d+', label.get_text()).group())\n",
    "        for label in axs[1].get_xticklabels()\n",
    "    ])\n",
    "    axs[1].set_xlabel(\"\")\n",
    "    axs[1].set_title(\"Por split\")\n",
    "    title = fig.suptitle(f\"{clf}: F1-score en test en validación cruzada\", y=1.1)\n",
    "    lgd = plt.legend(loc=\"lower center\", bbox_to_anchor=(-0.1, -0.8))\n",
    "    fig.savefig(\n",
    "    f\"{project_path}/visualizations/{file_name}.png\",\n",
    "    bbox_extra_artists=[lgd,title], bbox_inches='tight'\n",
    ")\n",
    "\n",
    "def print_best_estimator_info(gs_estimators: GridSearchCV) -> None:\n",
    "    best_params = \"\\n\\t-- \".join(\n",
    "        [f\"{k}: {v}\" for k, v in gs_estimators.best_params_.items()]\n",
    "    )\n",
    "    print(f\"\"\"\n",
    "    - Best Cross-Validation score : {gs_estimators.best_score_}\n",
    "    - Best parameters set:\\n\\t-- {best_params}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gridsearch = build_gridsearch(\n",
    "    clf=MultinomialNB(),\n",
    "    clf_params={\"clf__alpha\": [0.01, 0.1, 1.0]}\n",
    ")\n",
    "nb_gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gridsearch_cv_results = build_results_df(nb_gridsearch.cv_results_)\n",
    "nb_gridsearch_cv_results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gridsearch_cv_results2plot = build_results_df2plot(nb_gridsearch_cv_results)\n",
    "plot_results(nb_gridsearch_cv_results2plot, clf=\"Naive Bayes Multinomial\", file_name=\"clf__nb_cv.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_best_estimator_info(nb_gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nb = nb_gridsearch_cv_results[\n",
    "    nb_gridsearch_cv_results.index.str.contains(\"alpha=1.0\")\n",
    "    & nb_gridsearch_cv_results.index.str.contains(\"min_df=0.1\")\n",
    "    & nb_gridsearch_cv_results.index.str.contains(\"norm=l1\")\n",
    "    & nb_gridsearch_cv_results.index.str.contains(\"smooth_idf=False\")\n",
    "    & nb_gridsearch_cv_results.index.str.contains(\"sublinear_tf=False\")\n",
    "]\n",
    "selected_nb_params = \"\\n\\t-- \".join(selected_nb.index.tolist()[0].split('-'))\n",
    "print(f\"\"\"\n",
    "    - Selected Cross-Validation score: {selected_nb.mean_test_score.values[0]}\n",
    "    - Selected parameters set:\\n\\t-- {selected_nb_params}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more about LR solvers on: https://scikit-learn.org/stable/modules/linear_model.html#solvers\n",
    "lr_gridsearch = build_gridsearch(\n",
    "    clf = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=2023),\n",
    "    clf_params = {\"clf__penalty\": [\"l1\", \"l2\"], \"clf__C\": [0.1, 0.5, 1]}\n",
    ")\n",
    "lr_gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gridsearch_cv_results = build_results_df(lr_gridsearch.cv_results_)\n",
    "lr_gridsearch_cv_results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gridsearch_cv_results2plot = build_results_df2plot(lr_gridsearch_cv_results)\n",
    "plot_results(lr_gridsearch_cv_results2plot, clf=\"Regresión Logística\", file_name=\"clf__lr_cv.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_best_estimator_info(lr_gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lr = lr_gridsearch_cv_results[\n",
    "    lr_gridsearch_cv_results.index.str.contains(\"C=0.5\")\n",
    "    & lr_gridsearch_cv_results.index.str.contains(\"penalty=l1\")\n",
    "    & lr_gridsearch_cv_results.index.str.contains(\"min_df=0.1\")\n",
    "    & lr_gridsearch_cv_results.index.str.contains(\"norm=l1\")\n",
    "    & lr_gridsearch_cv_results.index.str.contains(\"smooth_idf=True\")\n",
    "    & lr_gridsearch_cv_results.index.str.contains(\"sublinear_tf=True\")\n",
    "]\n",
    "selected_lr_params = \"\\n\\t-- \".join(selected_lr.index.tolist()[0].split('-'))\n",
    "print(f\"\"\"\n",
    "    - Selected Cross-Validation score: {selected_lr.mean_test_score.values[0]}\n",
    "    - Selected parameters set:\\n\\t-- {selected_lr_params}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seleted_params(params:str) -> dict[str, dict[str,Any]]:\n",
    "    selected_params = dict()\n",
    "    key_value_params = [p.split(\"=\") for p in params.split(\"\\n\\t-- \")]\n",
    "    for key, value in key_value_params:\n",
    "        try:\n",
    "            value = eval(value)\n",
    "        except:\n",
    "            value = value\n",
    "        clf, param = key.split(\"__\")\n",
    "        if clf in selected_params:\n",
    "            selected_params[clf][param] = value\n",
    "        else:\n",
    "            selected_params[clf] = {param: value}\n",
    "    return selected_params\n",
    "\n",
    "def get_best_params(params: dict[str:Any]) -> dict[str, dict[str, Any]]:\n",
    "    selected_params = dict()\n",
    "    for key, value in params.items():\n",
    "        clf, param = key.split(\"__\")\n",
    "        if clf in selected_params:\n",
    "            selected_params[clf][param] = value\n",
    "        else:\n",
    "            selected_params[clf] = {param: value}\n",
    "    return selected_params\n",
    "\n",
    "def plot_nb_weights(df: pd.DataFrame, title:str, file_name:str):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(12,3), sharey=True)\n",
    "    sns.histplot(\n",
    "        data = df.melt(id_vars=[\"word\"], var_name=\"weight\"),\n",
    "        x=\"value\",\n",
    "        hue=\"weight\",\n",
    "        bins=30,\n",
    "        ax=axs[0]\n",
    "    )\n",
    "    axs[0].set_xlabel(\"\")\n",
    "    axs[0].set_ylabel(\"Cantidad de observaciones\")\n",
    "    axs[0].set_title(\"Pesos por categoría\")\n",
    "    axs[0].get_legend().set_title(\"Pesos\")\n",
    "    sns.histplot(\n",
    "        data = df.assign(diff=lambda x: x.pos-x.neg),\n",
    "        x=\"diff\",\n",
    "        bins=30,\n",
    "        ax=axs[1]\n",
    "    )\n",
    "    axs[1].set_title(\"Diferencia de pesos: $pos-neg$\")\n",
    "    title = fig.suptitle(title,  y=1.05)\n",
    "    fig.savefig(\n",
    "    f\"{project_path}/visualizations/{file_name}.png\",\n",
    "    bbox_extra_artists=[title], bbox_inches='tight'\n",
    ")\n",
    "\n",
    "def plot_lr_weights(df: pd.DataFrame, title:str, file_name:str):\n",
    "    df_copy = deepcopy(df)\n",
    "    df_copy.loc[df_copy.coef >= 0, \"weight\"] = \"pos\"\n",
    "    df_copy.loc[df_copy.coef < 0, \"weight\"] = \"neg\"\n",
    "    fig, ax = plt.subplots(figsize=(6,3))\n",
    "    sns.histplot(\n",
    "        data = df_copy,\n",
    "        x=\"coef\",\n",
    "        hue=\"weight\",\n",
    "        bins=30,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Cantidad de observaciones\")\n",
    "    ax.get_legend().set_title(\"Pesos\")\n",
    "    fig.suptitle(title)\n",
    "    fig.savefig(\n",
    "    f\"{project_path}/visualizations/{file_name}.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nb_params = get_seleted_params(selected_nb_params)\n",
    "selected_nb_pipeline = Pipeline([\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(lowercase=True, preprocessor=preprocess, **selected_nb_params[\"tfidf\"]),\n",
    "    ),\n",
    "    (\n",
    "        \"clf\",\n",
    "        MultinomialNB(**selected_nb_params[\"clf\"]\n",
    "        )\n",
    "    )\n",
    "])\n",
    "selected_nb_fi = selected_nb_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nb_weights = pd.DataFrame({\n",
    "        \"word\": selected_nb_fi[0].vocabulary_.keys(),\n",
    "        \"neg\": selected_nb_fi[1].feature_log_prob_[0],\n",
    "        \"pos\": selected_nb_fi[1].feature_log_prob_[1]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nb_weights(selected_nb_weights, title=\"Importancia de rasgos en Naive Bayes\", file_name=\"nb_selected_feature_importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb_params = get_best_params(nb_gridsearch.best_params_)\n",
    "best_nb_pipeline = Pipeline([\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(lowercase=True, preprocessor=preprocess, **best_nb_params[\"tfidf\"]),\n",
    "    ),\n",
    "    (\n",
    "        \"clf\",\n",
    "        MultinomialNB(**best_nb_params[\"clf\"]\n",
    "        )\n",
    "    )\n",
    "])\n",
    "best_nb_fi = best_nb_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb_weights = pd.DataFrame({\n",
    "        \"word\": best_nb_fi[0].vocabulary_.keys(),\n",
    "        \"neg\": best_nb_fi[1].feature_log_prob_[0],\n",
    "        \"pos\": best_nb_fi[1].feature_log_prob_[1]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nb_weights(best_nb_weights, title=\"Importancia de rasgos en Naive Bayes\", file_name=\"nb_best_feature_importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_target_pos = LabelEncoder()\n",
    "le_target_pos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lr_params = get_seleted_params(selected_lr_params)\n",
    "selected_lr_pipeline = Pipeline([\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(lowercase=True, preprocessor=preprocess, **selected_lr_params[\"tfidf\"]),\n",
    "    ),\n",
    "    (\n",
    "        \"clf\",\n",
    "        LogisticRegression(\n",
    "            multi_class=\"ovr\", solver=\"liblinear\", random_state=2023, **selected_lr_params[\"clf\"])\n",
    "    )\n",
    "])\n",
    "selected_lr_fi = selected_lr_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lr_features = selected_lr_fi[0].vocabulary_\n",
    "selected_lr_weights  = selected_lr_fi[1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lr_weights[selected_lr_weights<0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_params = get_best_params(lr_gridsearch.best_params_)\n",
    "best_lr_pipeline = Pipeline([\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(lowercase=True, preprocessor=preprocess, **best_lr_params[\"tfidf\"]),\n",
    "    ),\n",
    "    (\n",
    "        \"clf\",\n",
    "        LogisticRegression(\n",
    "            multi_class=\"ovr\", solver=\"liblinear\", random_state=2023, **best_lr_params[\"clf\"])\n",
    "    )\n",
    "])\n",
    "best_lr_fi = best_lr_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_weights = pd.DataFrame({\n",
    "        \"word\": best_lr_fi[0].vocabulary_.keys(),\n",
    "        \"coef\": best_lr_fi[1].coef_[0]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lr_weights(best_lr_weights, title=\"Importancia de ragos en Regresión Logística\", file_name=\"lr_best_feature_importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armar una RL para predecir el negativo y ver cuáles son las palabras más importantes\n",
    "# y contratas con las más importantes del positivo\n",
    "\n",
    "# visualización\n",
    "# armar un gráfico de barras para cada RL con las palabras más representativas en el eje y\n",
    "# y los valores en el eje x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
