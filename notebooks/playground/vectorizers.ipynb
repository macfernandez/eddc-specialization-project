{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFrequenciesVectorizer(CountVectorizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input=\"content\",\n",
    "        encoding=\"utf-8\",\n",
    "        decode_error=\"strict\",\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        preprocessor=None,\n",
    "        tokenizer=None,\n",
    "        stop_words=None,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer=\"word\",\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        vocabulary=None,\n",
    "        binary=False,\n",
    "        dtype=np.int64,\n",
    "        dimension: int = 300,\n",
    "        positive_values: str = \"\",\n",
    "        custom_stop_words: str = \"\",\n",
    "        n_custom_stop_words: int = 1\n",
    "        ) -> None:\n",
    "        super().__init__(\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer=analyzer,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype\n",
    "        )\n",
    "        self.dimension = dimension\n",
    "        self.custom_stop_words = custom_stop_words\n",
    "        self.n_custom_stop_words = n_custom_stop_words\n",
    "        self.positive_values = positive_values\n",
    "\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        super().fit(raw_documents)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, raw_documents:list[str], y:list[str]):\n",
    "        difference = self.calculate_metric(raw_documents, y)\n",
    "\n",
    "        if (len(difference)*2) <= (self.dimension):\n",
    "            vocabulary = difference.vocabulary.to_list()\n",
    "        else:\n",
    "            n = math.ceil(int(self.dimension / 2))\n",
    "            pos_voc = (\n",
    "                difference[difference[\"diff\"]>=0]\n",
    "                .sort_values(by=[\"diff\", \"pos\", \"neg\"], ascending=[False, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            neg_voc = (\n",
    "                difference[difference[\"diff\"]<0]\n",
    "                .sort_values(by=[\"diff\", \"neg\", \"pos\"], ascending=[True, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            vocabulary = pos_voc+neg_voc\n",
    "        self.vocabulary = vocabulary\n",
    "        return super().fit_transform(raw_documents, y)\n",
    "        \n",
    "    \n",
    "    def calculate_metric(self, raw_documents:list[str], y:list[str]):\n",
    "        total_frequencies = self._count_total_frequencies(raw_documents, y)\n",
    "        \n",
    "        negative_values = list(set(y).difference(set([self.positive_values])))[0]\n",
    "        \n",
    "        count_difference = (\n",
    "            pd.DataFrame({\n",
    "                \"diff\": total_frequencies.loc[self.positive_values]-total_frequencies.loc[negative_values],\n",
    "                \"pos\": total_frequencies.loc[self.positive_values],\n",
    "                \"neg\": total_frequencies.loc[negative_values]\n",
    "            })\n",
    "            .rename_axis(\"vocabulary\", axis=0)\n",
    "            .reset_index()\n",
    "        )\n",
    "        return count_difference\n",
    "\n",
    "\n",
    "    def _count_total_frequencies(self, raw_documents, y=None):\n",
    "        X = super().fit_transform(raw_documents, y)\n",
    "        total_frequencies = (\n",
    "            pd.DataFrame(X.toarray(), columns=self.get_feature_names_out(), index=y)\n",
    "            .rename_axis(\"LABEL\", axis=0)\n",
    "            .reset_index()\n",
    "            .groupby(\"LABEL\")\n",
    "            .sum()\n",
    "        )\n",
    "        if (self.custom_stop_words == \"zipf\"):\n",
    "            total_frequencies = self._remove_zipf_stopwords(total_frequencies)\n",
    "        return total_frequencies\n",
    "    \n",
    "    def _set_stopwords(self, raw_documents) -> list:\n",
    "        if isinstance(self.custom_stop_words, str) and (self.custom_stop_words == \"zipf\"):\n",
    "            self.stop_words = self.get_zipf_stopwords(raw_documents)\n",
    "        elif isinstance(self.custom_stop_words, list):\n",
    "            self.stop_words = self.custom_stop_words\n",
    "        elif self.custom_stop_words == None:\n",
    "            self.stop_words = self.custom_stop_words\n",
    "        else:\n",
    "            raise ValueError(\"stop_words must be either string ('zipf'), a list of strings or None.\")\n",
    "\n",
    "    def _remove_zipf_stopwords(self, frequencies):\n",
    "        stop_words = self.get_zipf_stop_words(frequencies)\n",
    "        return frequencies.drop(columns=stop_words)\n",
    "    \n",
    "    def get_zipf_stop_words(self, frequencies):\n",
    "        stop_words = (\n",
    "            frequencies\n",
    "            .sum(axis=0)\n",
    "            .sort_values(ascending=False)\n",
    "            .head(100)\n",
    "            .index\n",
    "            .tolist()\n",
    "        )\n",
    "        return stop_words\n",
    "    \n",
    "    def transform(self, raw_documents):\n",
    "        return super().transform(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProportionsVectorizer(CustomFrequenciesVectorizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input=\"content\",\n",
    "        encoding=\"utf-8\",\n",
    "        decode_error=\"strict\",\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        preprocessor=None,\n",
    "        tokenizer=None,\n",
    "        stop_words=None,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer=\"word\",\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        vocabulary=None,\n",
    "        binary=False,\n",
    "        dtype=np.int64,\n",
    "        dimension: int = 300,\n",
    "        positive_values: str = \"\",\n",
    "        custom_stop_words: str = \"\",\n",
    "        n_custom_stop_words: int = 1\n",
    "        ) -> None:\n",
    "        super().__init__(\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer=analyzer,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype,\n",
    "            dimension=dimension,\n",
    "            positive_values=positive_values,\n",
    "            custom_stop_words=custom_stop_words,\n",
    "            n_custom_stop_words=n_custom_stop_words\n",
    "        )\n",
    "    \n",
    "    def fit_transform(self, raw_documents:list[str], y:list[str]):\n",
    "        difference = self.calculate_metric(raw_documents, y)\n",
    "\n",
    "        if (len(difference)*2) <= (self.dimension):\n",
    "            vocabulary = difference.vocabulary.to_list()\n",
    "        else:\n",
    "            n = math.ceil(int(self.dimension / 2))\n",
    "            pos_voc = (\n",
    "                difference[difference[\"diff\"]>=0]\n",
    "                .sort_values(by=[\"diff\", \"pos\", \"neg\"], ascending=[False, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            neg_voc = (\n",
    "                difference[difference[\"diff\"]<0]\n",
    "                .sort_values(by=[\"diff\", \"neg\", \"pos\"], ascending=[True, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            vocabulary = pos_voc+neg_voc\n",
    "        self.vocabulary = vocabulary\n",
    "        return super().fit_transform(raw_documents, y)\n",
    "        \n",
    "    \n",
    "    def calculate_metric(self, raw_documents:list[str], y:list[str]):\n",
    "        total_frequencies = self._count_total_frequencies(raw_documents, y)\n",
    "\n",
    "        proportions = total_frequencies.div(total_frequencies.sum(axis=1), axis=0)\n",
    "        \n",
    "        negative_values = list(set(y).difference(set([self.positive_values])))[0]\n",
    "        \n",
    "        count_difference = (\n",
    "            pd.DataFrame({\n",
    "                \"diff\": proportions.loc[self.positive_values]-proportions.loc[negative_values],\n",
    "                \"pos\": proportions.loc[self.positive_values],\n",
    "                \"neg\": proportions.loc[negative_values]\n",
    "            })\n",
    "            .rename_axis(\"vocabulary\", axis=0)\n",
    "            .reset_index()\n",
    "        )\n",
    "        return count_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOddsRatioVectorizer(CustomProportionsVectorizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input=\"content\",\n",
    "        encoding=\"utf-8\",\n",
    "        decode_error=\"strict\",\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        preprocessor=None,\n",
    "        tokenizer=None,\n",
    "        stop_words=None,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer=\"word\",\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        vocabulary=None,\n",
    "        binary=False,\n",
    "        dtype=np.int64,\n",
    "        dimension: int = 300,\n",
    "        positive_values: str = \"\",\n",
    "        custom_stop_words: str = \"\",\n",
    "        n_custom_stop_words: int = 1\n",
    "        ) -> None:\n",
    "        super().__init__(\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer=analyzer,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype,\n",
    "            dimension=dimension,\n",
    "            positive_values=positive_values,\n",
    "            custom_stop_words=custom_stop_words,\n",
    "            n_custom_stop_words=n_custom_stop_words\n",
    "        )\n",
    "    \n",
    "    def fit_transform(self, raw_documents:list[str], y:list[str]):\n",
    "        difference = self.calculate_metric(raw_documents, y)\n",
    "\n",
    "        if (len(difference)*2) <= (self.dimension):\n",
    "            vocabulary = difference.vocabulary.to_list()\n",
    "        else:\n",
    "            n = math.ceil(int(self.dimension / 2))\n",
    "            pos_voc = (\n",
    "                difference[difference[\"diff\"]>=1]\n",
    "                .sort_values(by=[\"diff\", \"pos\", \"neg\"], ascending=[False, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            neg_voc = (\n",
    "                difference[difference[\"diff\"]<1]\n",
    "                .sort_values(by=[\"diff\", \"neg\", \"pos\"], ascending=[True, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            vocabulary = pos_voc+neg_voc\n",
    "        self.vocabulary = vocabulary\n",
    "        return super().fit_transform(raw_documents, y)\n",
    "        \n",
    "    \n",
    "    def calculate_metric(self, raw_documents:list[str], y:list[str]):\n",
    "        total_frequencies = self._count_total_frequencies(raw_documents, y)\n",
    "\n",
    "        proportions = total_frequencies.div(total_frequencies.sum(axis=1), axis=0)\n",
    "\n",
    "        negative_values = list(set(y).difference(set([self.positive_values])))[0]\n",
    "        \n",
    "        count_difference = (\n",
    "            pd.DataFrame({\n",
    "                \"pos\": proportions.loc[self.positive_values]/(1-proportions.loc[self.positive_values]),\n",
    "                \"neg\": proportions.loc[negative_values]/(1-proportions.loc[negative_values])\n",
    "            })\n",
    "            .assign(diff=lambda x: x[\"pos\"]/x[\"neg\"])\n",
    "            .rename_axis(\"vocabulary\", axis=0)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        return count_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogOddsRatioVectorizer(CustomOddsRatioVectorizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input=\"content\",\n",
    "        encoding=\"utf-8\",\n",
    "        decode_error=\"strict\",\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        preprocessor=None,\n",
    "        tokenizer=None,\n",
    "        stop_words=None,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer=\"word\",\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        vocabulary=None,\n",
    "        binary=False,\n",
    "        dtype=np.int64,\n",
    "        dimension: int = 300,\n",
    "        positive_values: str = \"\",\n",
    "        custom_stop_words: str = \"\",\n",
    "        n_custom_stop_words: int = 1\n",
    "        ) -> None:\n",
    "        super().__init__(\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer=analyzer,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype,\n",
    "            dimension=dimension,\n",
    "            positive_values=positive_values,\n",
    "            custom_stop_words=custom_stop_words,\n",
    "            n_custom_stop_words=n_custom_stop_words\n",
    "        )\n",
    "    \n",
    "    def fit_transform(self, raw_documents:list[str], y:list[str]):\n",
    "        difference = self._calculate(raw_documents, y)\n",
    "\n",
    "        if (len(difference)*2) <= (self.dimension):\n",
    "            vocabulary = difference.vocabulary.to_list()\n",
    "        else:\n",
    "            n = math.ceil(int(self.dimension / 2))\n",
    "            pos_voc = (\n",
    "                difference[difference[\"diff\"]>=0]\n",
    "                .sort_values(by=[\"diff\", \"pos\", \"neg\"], ascending=[False, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            neg_voc = (\n",
    "                difference[difference[\"diff\"]<0]\n",
    "                .sort_values(by=[\"diff\", \"neg\", \"pos\"], ascending=[True, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            vocabulary = pos_voc+neg_voc\n",
    "        self.vocabulary = vocabulary\n",
    "        return super().fit_transform(raw_documents, y)\n",
    "        \n",
    "    \n",
    "    def calculate_metric(self, raw_documents:list[str], y:list[str]):\n",
    "        count_difference = super().calculate_metric(raw_documents)\n",
    "        count_difference[\"diff\"] = np.log(count_difference[\"diff\"])\n",
    "\n",
    "        return count_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSmoothLogOddsRatioVectorizer(CustomProportionsVectorizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input=\"content\",\n",
    "        encoding=\"utf-8\",\n",
    "        decode_error=\"strict\",\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        preprocessor=None,\n",
    "        tokenizer=None,\n",
    "        stop_words=None,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer=\"word\",\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        vocabulary=None,\n",
    "        binary=False,\n",
    "        dtype=np.int64,\n",
    "        dimension: int = 300,\n",
    "        positive_values: str = \"\",\n",
    "        custom_stop_words: str = \"\",\n",
    "        n_custom_stop_words: int = 1\n",
    "        ) -> None:\n",
    "        super().__init__(\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer=analyzer,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype,\n",
    "            dimension=dimension,\n",
    "            positive_values=positive_values,\n",
    "            custom_stop_words=custom_stop_words,\n",
    "            n_custom_stop_words=n_custom_stop_words\n",
    "        )\n",
    "\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        super().fit(raw_documents)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, raw_documents:list[str], y:list[str]):\n",
    "        difference = self.calculate_metric(raw_documents, y)\n",
    "\n",
    "        if (len(difference)*2) <= (self.dimension):\n",
    "            vocabulary = difference.vocabulary.to_list()\n",
    "        else:\n",
    "            n = math.ceil(int(self.dimension / 2))\n",
    "            pos_voc = (\n",
    "                difference[difference[\"diff\"]>=0]\n",
    "                .sort_values(by=[\"diff\", \"pos\", \"neg\"], ascending=[False, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            neg_voc = (\n",
    "                difference[difference[\"diff\"]<0]\n",
    "                .sort_values(by=[\"diff\", \"neg\", \"pos\"], ascending=[True, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            vocabulary = pos_voc+neg_voc\n",
    "        self.vocabulary = vocabulary\n",
    "        return super().fit_transform(raw_documents, y)\n",
    "        \n",
    "    \n",
    "    def calculate_metric(self, raw_documents:list[str], y:list[str]):\n",
    "        total_frequencies = super().calculate_metric(raw_documents, y)\n",
    "\n",
    "        total_frequencies[[\"pos\", \"neg\"]] = total_frequencies[[\"pos\", \"neg\"]].applymap(\n",
    "            lambda x: x+0.5 if x == 0 else x\n",
    "        )\n",
    "\n",
    "        f_smooth_log_odds_diff = (\n",
    "            pd\n",
    "            .DataFrame({\n",
    "                \"pos\": total_frequencies[\"pos\"]/(1-total_frequencies[\"pos\"]),\n",
    "                \"neg\": total_frequencies[\"neg\"]/(1-total_frequencies[\"neg\"])\n",
    "            })\n",
    "            .assign(\n",
    "                diff=lambda x: np.log(x[\"pos\"]/x[\"neg\"])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return f_smooth_log_odds_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTfidfVectorizer(CustomProportionsVectorizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input=\"content\",\n",
    "        encoding=\"utf-8\",\n",
    "        decode_error=\"strict\",\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        preprocessor=None,\n",
    "        tokenizer=None,\n",
    "        stop_words=None,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer=\"word\",\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        vocabulary=None,\n",
    "        binary=False,\n",
    "        dtype=np.int64,\n",
    "        dimension: int = 300,\n",
    "        positive_values: str = \"\",\n",
    "        custom_stop_words: str = \"\",\n",
    "        n_custom_stop_words: int = 1,\n",
    "        log_idf: bool = False\n",
    "        ) -> None:\n",
    "        super().__init__(\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer=analyzer,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype,\n",
    "            dimension=dimension,\n",
    "            positive_values=positive_values,\n",
    "            custom_stop_words=custom_stop_words,\n",
    "            n_custom_stop_words=n_custom_stop_words\n",
    "        )\n",
    "        self.log_idf = log_idf\n",
    "\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        super().fit(raw_documents)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, raw_documents:list[str], y:list[str]):\n",
    "        difference = self.calculate_metric(raw_documents, y)\n",
    "\n",
    "        if (len(difference)*2) <= (self.dimension):\n",
    "            vocabulary = difference.vocabulary.to_list()\n",
    "        else:\n",
    "            n = math.ceil(int(self.dimension / 2))\n",
    "            pos_voc = (\n",
    "                difference[difference[\"diff\"]>=0]\n",
    "                .sort_values(by=[\"diff\", \"pos\", \"neg\"], ascending=[False, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            neg_voc = (\n",
    "                difference[difference[\"diff\"]<0]\n",
    "                .sort_values(by=[\"diff\", \"neg\", \"pos\"], ascending=[True, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            vocabulary = pos_voc+neg_voc\n",
    "        self.vocabulary = vocabulary\n",
    "        return super().fit_transform(raw_documents, y)\n",
    "        \n",
    "    \n",
    "    def calculate_metric(self, raw_documents:list[str], y:list[str]):\n",
    "        total_frequencies = super().calculate_metric(raw_documents, y)\n",
    "\n",
    "        vectorizer = CountVectorizer(lowercase=True)\n",
    "        X = vectorizer.fit_transform(raw_documents)\n",
    "        X = X.toarray()\n",
    "        tf_idf = (\n",
    "            pd.DataFrame(X, columns=vectorizer.get_feature_names_out())\n",
    "            .sum(axis=0)\n",
    "            .to_frame(\"df\")\n",
    "            .reset_index(names=\"vocabulary\")\n",
    "            .merge(total_frequencies, on=\"vocabulary\", how=\"right\")\n",
    "            [[\"vocabulary\", \"pos\", \"neg\", \"df\"]]\n",
    "        )\n",
    "        \n",
    "        if self.log_idf:\n",
    "            tf_idf[\"log_idf\"] = tf_idf.df.apply(lambda x: math.log(1/x))\n",
    "            tf_idf = (\n",
    "                tf_idf\n",
    "                .assign(\n",
    "                    pos=tf_idf.apply(lambda x: x.pos*x.log_idf, axis=1),\n",
    "                    neg=tf_idf.apply(lambda x: x.neg*x.log_idf, axis=1)\n",
    "                )\n",
    "                .assign(diff=lambda x: x.pos - x.neg)\n",
    "            )\n",
    "        else:\n",
    "            tf_idf = (\n",
    "                tf_idf\n",
    "                .assign(\n",
    "                    pos=tf_idf.apply(lambda x: x.pos/x.df, axis=1),\n",
    "                    neg=tf_idf.apply(lambda x: x.neg/x.df, axis=1)\n",
    "                )\n",
    "                .assign(diff=lambda x: x.pos - x.neg)\n",
    "            )\n",
    "\n",
    "        return tf_idf[[\"vocabulary\", \"diff\", \"pos\", \"neg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWordScoresVectorizer(CustomProportionsVectorizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input=\"content\",\n",
    "        encoding=\"utf-8\",\n",
    "        decode_error=\"strict\",\n",
    "        strip_accents=None,\n",
    "        lowercase=True,\n",
    "        preprocessor=None,\n",
    "        tokenizer=None,\n",
    "        stop_words=None,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer=\"word\",\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        max_features=None,\n",
    "        vocabulary=None,\n",
    "        binary=False,\n",
    "        dtype=np.int64,\n",
    "        dimension: int = 300,\n",
    "        positive_values: str = \"\",\n",
    "        custom_stop_words: str = \"\",\n",
    "        n_custom_stop_words: int = 1\n",
    "        ) -> None:\n",
    "        super().__init__(\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer=analyzer,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype,\n",
    "            dimension=dimension,\n",
    "            positive_values=positive_values,\n",
    "            custom_stop_words=custom_stop_words,\n",
    "            n_custom_stop_words=n_custom_stop_words\n",
    "        )\n",
    "\n",
    "    def fit_transform(self, raw_documents:list[str], y:list[str]):\n",
    "        difference = self.calculate_metric(raw_documents, y)\n",
    "\n",
    "        if (len(difference)*2) <= (self.dimension):\n",
    "            vocabulary = difference.vocabulary.to_list()\n",
    "        else:\n",
    "            n = math.ceil(int(self.dimension / 2))\n",
    "            pos_voc = (\n",
    "                difference[difference[\"diff\"]>=0]\n",
    "                .sort_values(by=[\"diff\", \"pos\", \"neg\"], ascending=[False, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            neg_voc = (\n",
    "                difference[difference[\"diff\"]<0]\n",
    "                .sort_values(by=[\"diff\", \"neg\", \"pos\"], ascending=[True, False, True])\n",
    "                .head(n)\n",
    "                .vocabulary\n",
    "                .to_list()\n",
    "            )\n",
    "            vocabulary = pos_voc+neg_voc\n",
    "        self.vocabulary = vocabulary\n",
    "        return super().fit_transform(raw_documents, y)\n",
    "        \n",
    "    \n",
    "    def calculate_metric(self, raw_documents:list[str], y:list[str]):\n",
    "        total_frequencies = self._count_total_frequencies(raw_documents, y)\n",
    "\n",
    "        proportions = total_frequencies.div(total_frequencies.sum(axis=1), axis=0)\n",
    "        \n",
    "        negative_values = list(set(y).difference(set([self.positive_values])))[0]\n",
    "        \n",
    "        wkw = (\n",
    "            (proportions.loc[self.positive_values]-proportions.loc[negative_values])/\n",
    "            (proportions.loc[self.positive_values]+proportions.loc[negative_values])\n",
    "        )\n",
    "        nkw = total_frequencies.sum(axis=0)\n",
    "\n",
    "        wkw_diff = (\n",
    "            pd\n",
    "            .DataFrame({\n",
    "                \"diff\": wkw*nkw,\n",
    "                \"pos\": wkw*nkw,\n",
    "                \"neg\": wkw*nkw,\n",
    "            })\n",
    "            .rename_axis(\"word\", axis=0)\n",
    "            .reset_index()\n",
    "        )\n",
    "        return wkw_diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddc-tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
